/// <reference types="node" />
import { ChildProcessWithoutNullStreams } from 'child_process';
import net from 'net';
import { Readable, Writable } from 'stream';
import { Logger } from './logger';
import EventEmitter from 'events';
import { CameraConfig, VideoConfig } from './configTypes';
import { CameraRecordingConfiguration, ReconfigureStreamRequest, SnapshotRequest, StartStreamRequest } from 'homebridge';
import { SessionInfo } from '../controller/streamingDelegate';
export declare class FFmpegParameters {
    progressPort: number;
    debug: boolean;
    processor?: string;
    private hideBanner;
    private useWallclockAsTimestamp;
    private inputSoure;
    private protocolWhitelist?;
    private inputCodec?;
    private inputFormat?;
    private output;
    isVideo: boolean;
    isAudio: boolean;
    isSnapshot: boolean;
    private analyzeDuration?;
    private probeSize?;
    private stimeout?;
    private readrate?;
    private codec;
    private codecOptions?;
    private bitrate?;
    private payloadType?;
    private ssrc?;
    private srtpSuite?;
    private srtpParams?;
    private format?;
    private fps?;
    private pixFormat?;
    private colorRange?;
    private filters?;
    private width?;
    private height?;
    private bufsize?;
    private maxrate?;
    private crop;
    private sampleRate?;
    private channels?;
    private flagsGlobalHeader;
    private numberFrames?;
    private delaySnapshot;
    private movflags?;
    private maxMuxingQueueSize?;
    private iFrameInterval?;
    private processAudio;
    private constructor();
    static forAudio(debug?: boolean): Promise<FFmpegParameters>;
    static forVideo(debug?: boolean): Promise<FFmpegParameters>;
    static forSnapshot(debug?: boolean): Promise<FFmpegParameters>;
    static forVideoRecording(debug?: boolean): Promise<FFmpegParameters>;
    static forAudioRecording(debug?: boolean): Promise<FFmpegParameters>;
    setResolution(width: number, height: number): void;
    usesStdInAsInput(): boolean;
    setInputSource(value: string): void;
    setInputStream(input: Readable): Promise<void>;
    setDelayedSnapshot(): void;
    setup(cameraConfig: CameraConfig, request: StartStreamRequest | ReconfigureStreamRequest | SnapshotRequest | undefined): void;
    setRTPTarget(sessionInfo: SessionInfo, request: StartStreamRequest): void;
    setOutput(output: string): void;
    setupForRecording(videoConfig: VideoConfig, configuration: CameraRecordingConfiguration): void;
    setTalkbackInput(sessionInfo: SessionInfo): Promise<void>;
    setTalkbackChannels(channels: number): void;
    private buildGenericParameters;
    private buildInputParamters;
    private buildEncodingParameters;
    private buildOutputParameters;
    private buildParameters;
    getProcessArguments(): string[];
    static getRecordingArguments(parameters: FFmpegParameters[]): string[];
    static getCombinedArguments(parameters: FFmpegParameters[]): string[];
    getStreamStartText(): string;
    hasCustomFfmpeg(): boolean;
    getCustomFfmpeg(): string;
}
export declare class FFmpeg extends EventEmitter {
    private process?;
    private name;
    private log;
    private progress?;
    private parameters;
    private ffmpegExec;
    stdin?: Writable;
    stdout?: Readable;
    private starttime?;
    private killTimeout?;
    constructor(name: string, parameters: FFmpegParameters | FFmpegParameters[], log: Logger);
    start(): void;
    getResult(input?: Buffer): Promise<Buffer>;
    startFragmentedMP4Session(): Promise<{
        socket: net.Socket;
        process?: ChildProcessWithoutNullStreams;
        generator: AsyncGenerator<{
            header: Buffer;
            length: number;
            type: string;
            data: Buffer;
        }>;
    }>;
    private parseFragmentedMP4;
    private readLength;
    stop(): void;
    private onProgressStarted;
    private onProcessError;
    private onProcessExit;
}
//# sourceMappingURL=ffmpeg.d.ts.map